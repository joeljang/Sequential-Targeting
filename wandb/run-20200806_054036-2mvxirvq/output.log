0/323712 [00:00<? ?it/s] wheel.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(batch.label, dtype=torch.long, device=self.device)
0/323712 [00:02<? ?it/s]  0 loss: 0.23336, acc: 0.84375: 0/323712 [00:10<? ?it/s]  0 loss: 0.23336, acc: 0.84375: 384/323712 [00:10<2:31:24 35.59it/s]  0 loss: 0.23336, acc: 0.84375: 448/323712 [00:11<1:59:00 45.27it/s]  0 loss: 0.23336, acc: 0.84375: 512/323712 [00:12<1:46:59 50.35it/s]  0 loss: 0.23336, acc: 0.84375: 576/323712 [00:12<1:31:07 59.10it/s]  0 loss: 0.23336, acc: 0.84375: 640/323712 [00:14<1:50:41 48.65it/s]  0 loss: 0.23336, acc: 0.84375: 640/323712 [00:15<1:50:41 48.65it/s]  0 loss: 0.22289, acc: 0.69034: 704/323712 [00:15<1:45:10 51.18it/s]  0 loss: 0.22289, acc: 0.69034: 768/323712 [00:16<1:28:43 60.67it/s]  0 loss: 0.22289, acc: 0.69034: 832/323712 [00:17<1:29:33 60.09it/s]  0 loss: 0.22289, acc: 0.69034: 896/323712 [00:18<1:37:02 55.44it/s]  0 loss: 0.22289, acc: 0.69034: 960/323712 [00:20<1:49:47 49.00it/s]  0 loss: 0.22289, acc: 0.69034: 1024/323712 [00:21<1:37:46 55.00it/s]  0 loss: 0.22289, acc: 0.69034: 1088/323712 [00:22<1:34:32 56.88it/s]  0 loss: 0.22289, acc: 0.69034: 1152/323712 [00:23<1:34:42 56.77it/s]  0 loss: 0.22289, acc: 0.69034: 1216/323712 [00:24<1:28:34 60.68it/s]  0 loss: 0.22289, acc: 0.69034: 1280/323712 [00:25<1:25:55 62.54it/s]  0 loss: 0.22289, acc: 0.69034: 1280/323712 [00:26<1:25:55 62.54it/s]  0 loss: 0.21518, acc: 0.69643: 1344/323712 [00:26<1:19:27 67.61it/s]  0 loss: 0.21518, acc: 0.69643: 1408/323712 [00:27<1:20:03 67.10it/s]  0 loss: 0.21518, acc: 0.69643: 1472/323712 [00:28<1:19:45 67.33it/s]  0 loss: 0.21518, acc: 0.69643: 1536/323712 [00:29<1:26:35 62.02it/s]  0 loss: 0.21518, acc: 0.69643: 1600/323712 [00:30<1:35:16 56.35it/s]  0 loss: 0.21518, acc: 0.69643: 1664/323712 [00:31<1:35:08 56.41it/s]  0 loss: 0.21518, acc: 0.69643: 1728/323712 [00:32<1:33:08 57.62it/s]  0 loss: 0.21518, acc: 0.69643: 1792/323712 [00:34<1:41:59 52.61it/s]  0 loss: 0.21518, acc: 0.69643: 1856/323712 [00:35<1:46:06 50.55it/s]  0 loss: 0.21518, acc: 0.69643: 1920/323712 [00:36<1:35:24 56.22it/s]  0 loss: 0.21518, acc: 0.69643: 1920/323712 [00:37<1:35:24 56.22it/s]  0 loss: 0.20862, acc: 0.70363: 1984/323712 [00:37<1:29:44 59.76it/s]  0 loss: 0.20862, acc: 0.70363: 2048/323712 [00:38<1:23:06 64.50it/s]  0 loss: 0.20862, acc: 0.70363: 2112/323712 [00:39<1:24:28 63.45it/s]  0 loss: 0.20862, acc: 0.70363: 2176/323712 [00:40<1:23:43 64.01it/s]  0 loss: 0.20862, acc: 0.70363: 2240/323712 [00:41<1:24:42 63.24it/s]  0 loss: 0.20862, acc: 0.70363: 2304/323712 [00:42<1:32:46 57.74it/s]  0 loss: 0.20862, acc: 0.70363: 2368/323712 [00:43<1:33:52 57.06it/s]  0 loss: 0.20862, acc: 0.70363: 2432/323712 [00:44<1:32:58 57.59it/s]  0 loss: 0.20862, acc: 0.70363: 2496/323712 [00:45<1:31:56 58.23it/s]  0 loss: 0.20862, acc: 0.70363: 2560/323712 [00:46<1:22:19 65.02it/s]  0 loss: 0.20862, acc: 0.70363: 