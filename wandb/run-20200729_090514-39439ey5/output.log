0/12544 [00:00<? ?it/s] wheel.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(batch.label, dtype=torch.long, device=self.device)
0/12544 [00:00<? ?it/s]  0 loss: 1.1953, acc: 0.26562: 640/12544 [00:05<01:36 123.81it/s]  0 loss: 1.1953, acc: 0.26562: 640/12544 [00:05<01:36 123.81it/s]  0 loss: 0.81031, acc: 0.58665: 1280/12544 [00:10<01:30 124.75it/s]  0 loss: 0.81031, acc: 0.58665: 1280/12544 [00:10<01:30 124.75it/s]  0 loss: 0.73877, acc: 0.61979: 1920/12544 [00:15<01:25 124.68it/s]  0 loss: 0.73877, acc: 0.61979: 1920/12544 [00:15<01:25 124.68it/s]  0 loss: 0.71694, acc: 0.62399: 2560/12544 [00:20<01:19 124.85it/s]  0 loss: 0.71694, acc: 0.62399: 2560/12544 [00:20<01:19 124.85it/s]  0 loss: 0.69982, acc: 0.63186: 3200/12544 [00:25<01:15 124.28it/s]  0 loss: 0.69982, acc: 0.63186: 3200/12544 [00:26<01:15 124.28it/s]  0 loss: 0.6911, acc: 0.6345:   3840/12544 [00:30<01:10 123.75it/s]  0 loss: 0.6911, acc: 0.6345: 3840/12544 [00:31<01:10 123.75it/s]  0 loss: 0.68033, acc: 0.64319: 4480/12544 [00:35<01:04 125.80it/s]  0 loss: 0.68033, acc: 0.64319: 4480/12544 [00:36<01:04 125.80it/s]  0 loss: 0.67148, acc: 0.65009: 5120/12544 [00:40<00:58 127.65it/s]  0 loss: 0.67148, acc: 0.65009: 5120/12544 [00:41<00:58 127.65it/s]  0 loss: 0.66707, acc: 0.65104: 5760/12544 [00:45<00:53 126.58it/s]  0 loss: 0.66707, acc: 0.65104: 5760/12544 [00:46<00:53 126.58it/s]  0 loss: 0.6641, acc: 0.65093:  6400/12544 [00:50<00:47 128.49it/s]  0 loss: 0.6641, acc: 0.65093: 6400/12544 [00:51<00:47 128.49it/s]  0 loss: 0.66091, acc: 0.65161: 7040/12544 [00:55<00:43 127.26it/s]  0 loss: 0.66091, acc: 0.65161: 7040/12544 [00:56<00:43 127.26it/s]  0 loss: 0.6567, acc: 0.65245:  7680/12544 [01:00<00:38 127.00it/s]  0 loss: 0.6567, acc: 0.65245: 7680/12544 [01:01<00:38 127.00it/s]  0 loss: 0.65182, acc: 0.65393: 8320/12544 [01:05<00:33 126.22it/s]  0 loss: 0.65182, acc: 0.65393: 8320/12544 [01:06<00:33 126.22it/s]  0 loss: 0.64678, acc: 0.65518: 8960/12544 [01:10<00:27 128.32it/s]  0 loss: 0.64678, acc: 0.65518: 8960/12544 [01:11<00:27 128.32it/s]  0 loss: 0.64243, acc: 0.65791: 9600/12544 [01:15<00:22 130.37it/s]  0 loss: 0.64243, acc: 0.65791: 9600/12544 [01:15<00:22 130.37it/s]  0 loss: 0.6383, acc: 0.65966:  10240/12544 [01:20<00:17 130.42it/s]  0 loss: 0.6383, acc: 0.65966: 10240/12544 [01:20<00:17 130.42it/s]  0 loss: 0.63201, acc: 0.66411: 10880/12544 [01:25<00:12 130.02it/s]  0 loss: 0.63201, acc: 0.66411: 10880/12544 [01:25<00:12 130.02it/s]  0 loss: 0.6274, acc: 0.66603:  11520/12544 [01:30<00:07 129.82it/s]  0 loss: 0.6274, acc: 0.66603: 11520/12544 [01:30<00:07 129.82it/s]  0 loss: 0.62382, acc: 0.66808: 12160/12544 [01:34<00:02 131.84it/s]  0 loss: 0.62382, acc: 0.66808: 12160/12544 [01:35<00:02 131.84it/s]  0 loss: 0.61895, acc: 0.67114: 12544/12544 [01:37<00:00 128.23it/s]  0 loss: 0.61895, acc: 0.67114: 
{"type": "train", "dataset": "combined12500", "epoch": 0, "loss": 0.6171446736574822, "acc": 0.6729323308270677}
| 0/1024 [00:00<?, ?it/s]wheel.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(batch.label, dtype=torch.long, device=self.device)
| 256/1024 [00:00<00:00, 2140.71it/s]| 448/1024 [00:00<00:00, 1898.37it/s]| 576/1024 [00:00<00:00, 1585.51it/s]| 704/1024 [00:00<00:00, 1275.61it/s]| 832/1024 [00:00<00:00, 996.30it/s] | 960/1024 [00:00<00:00, 729.19it/s]| 1024/1024 [00:01<00:00, 872.80it/s]
[1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0]
[0.80223285 0.66666667]
{"type": "test", "dataset": "test_jj", "epoch": 0, "accuracy": 0.7517517517517518, "precision": 0.7303147791097326, "recall": 0.7422239365219307, "f1score": 0.7344497607655502}
Traceback (most recent call last):
  File "wheel.py", line 201, in <module>
  File "wheel.py", line 137, in train
    wandb.log({'Accuracy':accuracy,'Precision':prec,'Recall':recall,'F1Score':f1score,'0F1':f1s[0],'1F1':f1s[1],'2F1':f1s[2]})
IndexError: index 2 is out of bounds for axis 0 with size 2
